version: '3.8'

services:
  comfyui:
    build:
      context: .
      dockerfile: Dockerfile
    image: runpod-comfyui:latest
    container_name: comfyui

    # GPU support
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # Environment variables
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - DOWNLOAD_MODELS=false  # Set to true to download base models
      - AUTO_UPDATE=false      # Set to true to auto-update ComfyUI
      - DISABLE_AUTO_LAUNCH=true
      - COMFYUI_PREVIEW_METHOD=auto
      # Add custom ComfyUI arguments here
      # - COMFYUI_ARGS=--highvram

    # Port mapping
    ports:
      - "8188:8188"

    # Volume mounts for persistent storage
    volumes:
      # Models directory - stores all AI models
      - ./models:/workspace/ComfyUI/models
      # Output directory - generated images
      - ./output:/workspace/ComfyUI/output
      # Input directory - source images for img2img, etc.
      - ./input:/workspace/ComfyUI/input
      # Custom nodes - additional ComfyUI extensions
      - ./custom_nodes:/workspace/ComfyUI/custom_nodes
      # Workflows - saved ComfyUI workflows
      - ./workflows:/workspace/ComfyUI/workflows
      # General storage
      - ./storage:/workspace/storage

    # Restart policy
    restart: unless-stopped

    # Network mode (use host for better performance)
    network_mode: bridge

    # Shared memory size (important for data loading)
    shm_size: '16gb'

    # Resource limits (optional, adjust based on your system)
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '8'
    #       memory: 32G
    #     reservations:
    #       cpus: '4'
    #       memory: 16G

# Optional: Add a network if you want to run multiple services
networks:
  default:
    driver: bridge

# Named volumes (optional, if you prefer Docker-managed volumes)
# volumes:
#   models:
#   output:
#   input:
#   custom_nodes:
#   workflows:
#   storage: