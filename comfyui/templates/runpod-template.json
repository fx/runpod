{
  "name": "ComfyUI with Configuration System",
  "imageName": "ghcr.io/fx/runpod-comfyui:base",
  "description": "ComfyUI with flexible configuration system. Supports base, flux, sdxl-pony, and video variants.",
  "volumeInGb": 20,
  "containerDiskInGb": 10,
  "minVcpuCount": 2,
  "minMemoryInGb": 8,
  "gpuTypeId": "NVIDIA RTX A4000",
  "ports": "8188/http",
  "startJupyter": false,
  "startSsh": true,
  "env": [
    {
      "key": "CONFIG_NAME",
      "value": "base",
      "description": "Configuration variant to load (base, flux, sdxl-pony, video)"
    },
    {
      "key": "DOWNLOAD_MODELS",
      "value": "true",
      "description": "Download models on startup"
    },
    {
      "key": "AUTO_UPDATE",
      "value": "false",
      "description": "Auto-update ComfyUI on startup"
    },
    {
      "key": "COMFYUI_ARGS",
      "value": "",
      "description": "Additional ComfyUI arguments (--highvram, --lowvram, etc)"
    },
    {
      "key": "HF_TOKEN",
      "value": "{{ RUNPOD_SECRET_HF_TOKEN }}",
      "description": "HuggingFace token for gated models (uses RunPod secret HF_TOKEN)"
    }
  ],
  "dockerArgs": "",
  "volumeMountPath": "/runpod",
  "readme": "## ComfyUI on RunPod\n\nThis template provides ComfyUI with a flexible configuration system.\n\n### Available Variants\n- **base**: Minimal installation with SD 1.5\n- **flux**: FLUX models for high-quality generation\n- **sdxl-pony**: SDXL and Pony models\n- **video**: Video generation models\n\n### First Run\nOn first run, the container will:\n1. Install PyTorch and dependencies (~5 minutes)\n2. Download selected models if DOWNLOAD_MODELS=true\n3. Install custom nodes from configuration\n\n### Access\nComfyUI will be available at:\n- HTTP: `https://{pod-id}-8188.proxy.runpod.net`\n- Direct: Port 8188\n\n### GPU Memory Settings\n- 48GB+ (A6000, A100): Set COMFYUI_ARGS=--highvram\n- 24GB (RTX 4090, A5000): Leave empty (auto)\n- 8-16GB: Set COMFYUI_ARGS=--lowvram\n- <8GB: Set COMFYUI_ARGS=--cpu\n\n### Persistent Storage\nModels and outputs are stored in /runpod-volume and persist across restarts."
}
